{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For classification, we will be using the popular Amazon Food Reviews Dataset Corpus , where given the reviews text , We should be able to identify whether a given Review is positive or not\n",
    "\n",
    "\n",
    "Classification can be represented as\n",
    "\n",
    "y = f(x)\n",
    "\n",
    "where x is the review / input to the Machine learning Model\n",
    "\n",
    "f(x) is the ML model\n",
    "\n",
    "y is the class/ output of the resultset\n",
    "\n",
    "In case of Amazon Food Reviews dataset, y indicates a positive or negative review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Amazon Food review Dataset, we can have 2 possibe output values, either positive or negative (0,1),\n",
    "\n",
    "This is known as a 2-Class Classification or a Binary Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For MNIST Data set where we have classification of Digits from (0,1,2,3,4,5,6,7,8,9) , this is called a 10 Class Classification problem, or a Multi Class classificatiion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When in y = f(x),\n",
    "y is not part of a  small finite set of classes\n",
    "\n",
    "For eg. given a {race,gender, age, weight} of a persion, we need to predict the height of a person\n",
    "\n",
    "Here, height is a continuous value, and it cannot be limited to particular class, this is a type of a regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K- nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an Xq , given we have K-nn of Xq,\n",
    "\n",
    "we need to classify Xq based o its nearby value\n",
    "\n",
    "Supose \n",
    "K = 3 and the nerby 3 values are (positive, positive, positive), then it is safe to assume that Xq is also positive\n",
    "\n",
    "If 3 values are (positive, positive, negative),here we have a concept of Majority Vote, so based on that Xq value is positive\n",
    "\n",
    "If K =4 and nearby values are  (positive, positive, negative, negative), then avoid this result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Failure cases for K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"FailureOfKNN.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"EuclideanDistance.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidean Distance is nothing but shortest line between two data points or 2 Vectors\n",
    "\n",
    "Euclidean Distance between two points x1 and x2 = L2 norm of (x1-x2) =||x1-x2||2\n",
    "\n",
    "\n",
    "Here , note that Distance is always between 2 points and norm is for a vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Euclidean Distance ||x1-x2||2 = sqrt(sum(x1i-x2i)^2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manhattan Distance \n",
    "\n",
    "\n",
    "<img src='ManhattanDist.png'>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minkowsky Distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Minkowsky distance we take the p norm of the D-Dimensional Vecotr\n",
    "\n",
    "If p=2, Minkowsky distance  = Euclidean Distance\n",
    "\n",
    "If p =1, Minkowsky Distance = Manhattan Distance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Minkowsky.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hamming Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hamming Disrtance is nothing but the binary difference between 2 sentences or ny Logical data\n",
    "\n",
    "Eg take:\n",
    "    Difference between 010 and 011 =1\n",
    "    \n",
    "    Difference between 0010 and 0111 =2\n",
    "    \n",
    "    Difference between 10010 and 10111 =3\n",
    "    \n",
    " Above Distances are based on the number of digits (0 or 1 ) are different between given 2 group of binary sequences   \n",
    "    \n",
    "    \n",
    "    Refer below img for better clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='HammingDistance.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cosine Distance and Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When distance between 2 points xx1 and x2 is more, this means they are less similar and Vice Versa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='CosineDistance.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine Similarity Illustration using Cos thetamapping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'CosineSimilarity.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 - cos-sim(x1,x2) = cos-dist(x1,x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formula for Cosine Similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'CosineSimilarityFormula.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation between Euclidean Distance and Cosine Distance formula\n",
    "\n",
    "given that both x1 and x2 are unit vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Euc-CosRelation.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 18.8 Measuring Effectiveness of K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: SplitData of Amazo Food Reviews Dn into 2 parts ie. Training and Testing Dataset.\n",
    "\n",
    "Step 2 : Train the K-NN model on Training Data \n",
    "\n",
    "Step 3: Test the K-NN model on testing data\n",
    "\n",
    "Step 4: After testing keep a count of how many times the model using K-NN trained on Amazon Food Reviews Training data predicted \n",
    "correct result\n",
    "\n",
    "Step 5: The accracy of K-NN on Amazon Food reviews fata can be calculated as No. of times correct output predicted /Total no of o/p in Test data\n",
    "\n",
    "Step 6: Accuracy always lies between 0 and 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of TIme/Space complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time complexity = O(nd)\n",
    "Space complexity =O(nd)\n",
    "\n",
    "where n = number of data points (in Amazon food reviews in our case)\n",
    "d = training data matrix  points (evaluated using BoW, Tf-Idf,W2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Surface of K-NN where K=1,2,..N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"DecisionSurface.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Underfitting and Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a function to data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = 'Over-Under-Fitting.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Need for cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"Accuracy.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using D training dataset on Amazon Food reviews dataset with k-NN with K=6 we get 96 % accuracy as per above figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to keep in mind that the algorith which is trained on Dtrain dataset should well extremely well on new Unseen Data oints, this term is known as generalization\n",
    "\n",
    "Sice we used Dtest data to calculate accuracy ie. No. of correctly classified data/Total no. of points in Dataset Dtest, so 6-NN cannot be the correct measure for accuracy of the model\n",
    "\n",
    "\n",
    "TO eliminate this, we have aconcept of CrossValidation\n",
    "We split Dataset into 3 parts,\n",
    "1. Dtrain\n",
    "\n",
    "2. Dtest\n",
    "\n",
    "3. Dcrossvalidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So,\n",
    "we will be using Dtrain Data to calculate Neearest Neighbor\n",
    "we will use Dcv to calculate K\n",
    "And we will NEVER touch Dtest data to evaluate accuracy or build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We make an 80-20 split for Dtrain and Dtest\n",
    "2. Now we split Randomly Dtrain  Dataset into D1, D2, D3 D4\n",
    "3. Now in below diagram is illustrated as to how to leverage all the 4 splitted parts of Dtrain dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='KFlod.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much should be the value of K for F-Fold Cross Validation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well the rule of thumb is to use k=10 while perofrming K-Fold Cross Validation. There is no concrete proodf as to why we do it, but more the number of folds , more we are adding to the complication of the algorith"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time taken to perofrm K-Fold Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time taken to evaluate the correct/optimal K in K-NN also icreases by k' times when we do K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VIsualizing Dtrain, Dcv, Dtest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we randomly sample our Data, we wil sometimes get outliers in the dataset as illustrated in the below figure\n",
    "\n",
    "Some observations are as below,\n",
    "\n",
    "1. Dtrain and Dcv data do not perfectly overlap each other\n",
    "2. If there are many +ve/-ve points from Dtrain in a region, then it is highly likely to find many +ve/-ve points from Dcv in that region respectively\n",
    "3. If there are few +ve/-ve points from Dtrain in a region, then it is highly likely to find very few +ve/-ve points from Dcv in that region respectively. Suc poins are referred as noise points, outlier points, erronous points\n",
    "\n",
    "\n",
    "Above  points are also applicable to Dtest data as well, as log as we are samplingthe data randomly \n",
    "\n",
    "\n",
    "\n",
    "<img src = 'VisualizeDtrain.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to determin Underfitting and Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer the figure below\n",
    "\n",
    "\n",
    "If training error is high as well as cross validation error is also high, this means that the mode is underfit, ie. it does not adapt well to neither training nor cross validation data\n",
    "\n",
    "If training error is low BUT cross validation error is high, this means that the mode is overfit, ie. it does not adapt well to neither training nor cross validation data\n",
    "\n",
    "\n",
    "Even in the middle area which is considered to be the areawhere the model generalizes to Data really well, we have a trade off for tarining and testing error. Means that there will be some error in training and cross vvalidation data \n",
    "\n",
    "\n",
    "\n",
    "<img src = 'OverUnderFittingMeasure.png'>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Based Splitting of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a Machine Learning algorithm we can split the given dataset into training and test data. We can either split randomly or use time based splitting.\n",
    "\n",
    "For time based splitting we need a timestamp as one of the attributes / features.\n",
    "\n",
    "Like in case of e-commerce website we can have reviews for various products. These reviews can have timestamps also. In such scenarios it’s better to use time-based strategy.\n",
    "\n",
    "To do this we can first sort the reviews using timestamp and then do the split.\n",
    "\n",
    "Sort data by time.\n",
    "Split – Training (80%) and Testing(20%)\n",
    "This approach can give better accuracy. Since the testing data will be more recent and hence better prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighed K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='WeighedKNN.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure \n",
    "\n",
    "Weight = 1/distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time and Space complexity of K-nn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Time complexity : O(n) given that d and K are very small\n",
    "2. Space complexity : O(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will use KD-Tree to reduce time complexity of K-NN from O(n) --> O(logn)\n",
    "\n",
    "So that when n=1024, log n =10 so a signiicant reduction in time for execution ogf algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='BST.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Binary Search Tree, the time complexityto search is O(log n) which is equal to the depth of the BST\n",
    "\n",
    "1. ie. no. of elements is 1, depth = 1 \n",
    "2. no of elements is 4 , depth is 2\n",
    "3. no of elements is 8, depth is 3 \n",
    "4. no of elements is 16 , depth is 4 likewise\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to build a Kd-tree "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer Wikipedia or other learning Materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashing vs Locality-Sensitive Hashing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Locally sensitive hashing is useful and a powerful Nearest enighbour search algo, specifically when d-dimension is very large\n",
    "\n",
    "LSH is based on Hashing algo, ie Hashtable data structure which is Dictionary(Key,value) in Python\n",
    "\n",
    "Consider an array a = [2,3,4,5,6,5,8]\n",
    " In a normal search, it will take O(n) time to comppute the index of nth element\n",
    " With Hashing, this is redyced to O(1)\n",
    " \n",
    " <img src = 'LSH.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locality-Sensitive Hashing for Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
